# Multi-Task-News-Intelligence-System
End-to-end multi-task NLP system for news analytics performing article classification, named entity recognition, and summarization using from-scratch ML/DL models and pretrained transformers. Deployed on AWS with Streamlit UI, S3 model storage, and RDS logging.

‚úÖ Project Blueprint
Multi-Task News Intelligence System:
Classification, NER, and Summarization using From-Scratch Models & Pretrained Transformers
Cloud Deployment: Hugging Face, Streamlit, AWS EC2, S3, and RDS

üìå Problem Statement
Build an end-to-end multi-task NLP system that processes news articles to perform:
1.	Text Classification
Predict category ‚Üí Politics, Business, Tech, Sports, Entertainment, etc.
2.	Named Entity Recognition (NER)
Extract entities ‚Üí PERSON, ORG, LOC, DATE, PRODUCT, etc.
3.	Summarization
Generate concise summaries ‚Üí Extractive + Abstractive
For each task you must build:
‚Ä¢	From-Scratch Traditional ML Models
‚Ä¢	From-Scratch DL Models
‚Ä¢	Pretrained Transformer Models
The system must be deployed as a unified Streamlit/Gradio web app on AWS EC2, using S3 for model storage and RDS for logging user activity

üéØ Objectives
‚Ä¢	Implement classification, NER, summarization pipelines under one system.
‚Ä¢	Build scratch baselines: ML (BoW/TF-IDF), DL (CNN/LSTM/BiLSTM/Seq2Seq).
‚Ä¢	Fine-tune transformers ‚Üí BERT, DistilBERT, BART, T5, RoBERTa.
‚Ä¢	Compare feature representations (BoW vs TF-IDF vs Word2Vec).
‚Ä¢	Deploy full system ‚Üí EC2 + S3 + RDS + Streamlit.
‚Ä¢	Log all user interactions (task, model, output, time, etc.).

üèóÔ∏è Approach & Architecture
1. Data Preparation
Dataset: Microsoft PENS ‚Äì Personalized News Headlines / Articles
2. Preprocessing
Common text cleaning:
‚úî Remove HTML, emojis, URLs
‚úî Normalize punctuation
‚úî Lower-casing (except transformer or NER models)
‚úî Whitespace normalization
Tokenization & stopwords:
‚Ä¢	BoW/TF-IDF ‚Üí remove stopwords
‚Ä¢	NER ‚Üí keep casing + token boundaries
Labeling and sequences:
‚Ä¢	Classification ‚Üí LabelEncoder
‚Ä¢	NER ‚Üí BIO/BILOU tagging
‚Ä¢	Summarization ‚Üí truncation + length control
Feature Representations
‚Ä¢	BoW / TF-IDF (CountVectorizer / TfidfVectorizer)
‚Ä¢	Word2Vec / GloVe embeddings
‚Ä¢	Transformer tokenization (BERT, T5, BART)
üìä 3. Exploratory Data Analysis
Classification EDA:
‚Ä¢	Category distribution
‚Ä¢	Per-category word counts
‚Ä¢	Word clouds / top keywords
NER EDA:
‚Ä¢	Entity type distribution
‚Ä¢	Examples of high-entity-density sentences
Summarization EDA:
‚Ä¢	Article vs summary lengths
‚Ä¢	Compression ratios
General text stats:
‚Ä¢	Vocabulary size
‚Ä¢	Frequent n-grams
‚Ä¢	TF-IDF heatmaps per topic

ü§ñ 4. Model Building
You will build 3 model families per task:

| Task           | ML Baseline       | Custom DL           | Transformer           |
| -------------- | ----------------- | ------------------- | --------------------- |
| Classification | LogReg, SVM, NB   | CNN / LSTM / BiLSTM | BERT, DistilBERT      |
| NER            | Rule-based        | BiLSTM / BiLSTM-CRF | BERT Token Classifier |
| Summarization  | TF-IDF / TextRank | Seq2Seq (LSTM)      | T5, BART              |

4.1 Text Classification
[1] ML Baselines (BoW / TF-IDF)
‚Ä¢	Logistic Regression
‚Ä¢	SVM
‚Ä¢	Multinomial Naive Bayes
[2] DL Baseline (Word2Vec + CNN/LSTM/BiLSTM)
‚Ä¢	Embedding layer (Word2Vec / GloVe / trainable)
‚Ä¢	CNN or LSTM/BiLSTM
‚Ä¢	Dropout + regularization
‚Ä¢	Early stopping
[3] Pretrained Transformers
‚Ä¢	BERT / DistilBERT / RoBERTa
‚Ä¢	Fine-tuning (Trainer API or custom loop)
________________________________________
4.2 Named Entity Recognition (NER)
[1] Rule-Based Baseline
‚Ä¢	Regex patterns for:
o	Capitalized names
o	Dates
o	Organizations
‚Ä¢	Used as a weak baseline
[2] DL Model: BiLSTM or BiLSTM-CRF
‚Ä¢	Word embeddings (Word2Vec/GloVe)
‚Ä¢	Optional char embeddings
‚Ä¢	BiLSTM ‚Üí Linear ‚Üí CRF
[3] Transformer NER
‚Ä¢	BERT-base-cased
‚Ä¢	RoBERTa-large-NER
‚Ä¢	Fine-tuning for token classification
________________________________________
4.3 Summarization
[1] Extractive Baseline
‚Ä¢	TF-IDF sentence scoring
‚Ä¢	TextRank (optional)
‚Ä¢	Top-k sentence selection
[2] Custom Seq2Seq (LSTM/GRU)
‚Ä¢	LSTM/GRU encoder
‚Ä¢	LSTM/GRU decoder with attention
‚Ä¢	Teacher forcing
‚Ä¢	Scheduled sampling
[3] Transformer Summarizers
‚Ä¢	T5-small / T5-base
‚Ä¢	BART-base
‚Ä¢	Pegasus (optional)
‚Ä¢	Evaluate with ROUGE
______________________________
üìà 5. Evaluation Framework

| Task           | Metrics                            |
| -------------- | ---------------------------------- |
| Classification | Accuracy, Precision, Recall, F1    |
| NER            | Precision, Recall, F1 (per entity) |
| Summarization  | ROUGE-1, ROUGE-2, ROUGE-L          |

Classification
‚Ä¢	Accuracy, Precision, Recall, F1
‚Ä¢	Confusion matrix
‚Ä¢	Compare:
o	BoW vs TF-IDF
o	Word2Vec vs Transformer
NER
‚Ä¢	Precision, Recall, F1 (micro, macro, per entity)
‚Ä¢	Compare:
o	Rule-based vs BiLSTM vs BERT NER
Summarization
‚Ä¢	ROUGE-1, ROUGE-2, ROUGE-L
‚Ä¢	Human evaluation for coherence
‚Ä¢	Compare extractive vs Seq2Seq vs T5/BART

üñ•Ô∏è 6. Unified Streamlit Application
Inputs:
‚Ä¢	Text box / file upload
Task selector:
‚Ä¢	Classification
‚Ä¢	NER
‚Ä¢	Summarization
Model selector:
‚Ä¢	From-Scratch ML
‚Ä¢	From-Scratch DL
‚Ä¢	Pretrained Transformer
Outputs:
‚Ä¢	Classification: label + confidence
‚Ä¢	NER: highlighted entities
‚Ä¢	Summarization: summary (with model comparison option)

‚òÅÔ∏è 7. AWS Cloud Deployment

| AWS Service | Purpose                             |
| ----------- | ----------------------------------- |
| EC2         | Hosts Streamlit application         |
| S3          | Stores trained models & vectorizers |
| RDS         | Stores inference & user logs        |
| IAM         | Secure access control               |

7.1 RDS (PostgreSQL/MySQL) ‚Äì User Interaction Logging

| Column Name  | Data Type | Description                          |
| ------------ | --------- | ------------------------------------ |
| id           | INT (PK)  | Unique log ID                        |
| user_id      | VARCHAR   | User identifier                      |
| timestamp    | TIMESTAMP | Inference time                       |
| task_type    | VARCHAR   | Classification / NER / Summarization |
| model_family | VARCHAR   | ML / DL / Transformer                |
| model_name   | VARCHAR   | Model used                           |
| input_length | INT       | Input text length                    |
| output_label | VARCHAR   | Predicted class / summary            |
| error_flag   | BOOLEAN   | Error indicator                      |

Store fields:
‚Ä¢	user_id
‚Ä¢	timestamp
‚Ä¢	task_type
‚Ä¢	model_family
‚Ä¢	model_name
‚Ä¢	input_length
‚Ä¢	output_label/summary_length
‚Ä¢	error_flag
Use:
‚Ä¢	SQLAlchemy / psycopg2 / mysqlclient
‚Ä¢	Credentials via env vars or AWS Secrets Manager

7.2 S3 ‚Äì Model Artifact Storage

| Path                   | Contents                   |
| ---------------------- | -------------------------- |
| models/classification/ | ML, DL, Transformer models |
| models/ner/            | NER models                 |
| models/summarization/  | Summarization models       |
| artifacts/             | Vectorizers, encoders      |

Store:
‚Ä¢	ML models (.pkl)
‚Ä¢	DL weights (.pt)
‚Ä¢	Transformer checkpoints
‚Ä¢	Vectorizers, label encoders, tokenizers
‚Ä¢	Word2Vec models
Folder structure example:
s3://nlp-multitask/
    models/classification/
    models/ner/
    models/summarization/
    preprocessors/
Lazy loading recommended for speed.

7.3 EC2 ‚Äì Application Hosting
Steps:
1.	Launch Ubuntu EC2
2.	Install Python, PyTorch, Transformers
3.	Pull project from GitHub
4.	Configure env variables
5.	Pull models from S3
6.	Connect to RDS (private subnet recommended)
7.	Run Streamlit on port 8501
8.	Optional: reverse proxy with Nginx + HTTPS

üèÅ Expected Result
A production-style, cloud-deployed, multi-task NLP system with:
‚Ä¢	Robust classification
‚Ä¢	Accurate NER
‚Ä¢	High-quality summarization
‚Ä¢	Unified user-friendly interface
‚Ä¢	Reliable logging + analytics
‚Ä¢	Scalable architecture

üìö Project Evaluation Criteria
‚Ä¢	Functionality
‚Ä¢	Model performance
‚Ä¢	Deployment quality
‚Ä¢	UI/UX
‚Ä¢	Logging and monitoring
‚Ä¢	Documentation (README + diagrams)
‚Ä¢	Code quality and explainability

| Component        | Description                           |
| ---------------- | ------------------------------------- |
| Input Layer      | News article text (paste or upload)   |
| Preprocessing    | Cleaning, tokenization, vectorization |
| Task Selector    | Classification / NER / Summarization  |
| Model Layer      | ML, DL (from scratch), Transformer    |
| Inference Engine | Runs selected model                   |
| Output Layer     | Labels, entities, summaries           |
| Logging Layer    | Stores inference metadata             |
| UI               | Streamlit web application             |
| Cloud            | AWS EC2, S3, RDS                      |

FOLDER STRUCTURE
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ classification/
|        |-ml
|        |-dl
|        |-Transformer
‚îÇ   ‚îú‚îÄ‚îÄ ner/
|        |-ml
|        |-dl
|        |-Transformer
‚îÇ   ‚îî‚îÄ‚îÄ summarization/
|        |-ml
|        |-dl
|        |-Transformer
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ news.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md













