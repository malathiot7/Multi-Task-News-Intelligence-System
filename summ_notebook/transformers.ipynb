{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb86187",
   "metadata": {},
   "source": [
    "If you want, I‚Äôll now give:\n",
    "\n",
    "* üî• **Notebook-2 code**\n",
    "* üìä **Final comparison table (scratch vs pretrained)**\n",
    "* üß† **Viva explanation**\n",
    "\n",
    "Just say **‚Äúgive pretrained notebook‚Äù**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe308f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers rouge-score sentencepiece torch --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f357cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0648d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Malathi M/OneDrive/Documents/MDTE25/guvi final project/Main project/news.tsv.zip\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e84b875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Headline</th>\n",
       "      <th>News body</th>\n",
       "      <th>Title entity</th>\n",
       "      <th>Entity content</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N32957</td>\n",
       "      <td>foodanddrink</td>\n",
       "      <td>videos</td>\n",
       "      <td>How to Make Spaghetti Pudding</td>\n",
       "      <td>Similar to bread pudding or rice pudding, this...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>How to Make Spaghetti Pudding Similar to bread...</td>\n",
       "      <td>How to Make Spaghetti Pudding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N15327</td>\n",
       "      <td>sports</td>\n",
       "      <td>basketball_nba</td>\n",
       "      <td>Report: Dolan was not interested in paying max...</td>\n",
       "      <td>As if that's the only thing it hinged on NBA f...</td>\n",
       "      <td>{'Dolan': 'Pat Dolan', 'Durant': 'Kevin Durant'}</td>\n",
       "      <td>{'Pat Dolan': {'type': 'item', 'id': 'Q7143387...</td>\n",
       "      <td>Report: Dolan was not interested in paying max...</td>\n",
       "      <td>Report: Dolan was not interested in paying max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N117490</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>House panel votes to subpoena Kellyanne Conway</td>\n",
       "      <td>The House Oversight Committee has voted to sub...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>House panel votes to subpoena Kellyanne Conway...</td>\n",
       "      <td>House panel votes to subpoena Kellyanne Conway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N100097</td>\n",
       "      <td>finance</td>\n",
       "      <td>markets</td>\n",
       "      <td>The 'Texas Miracle' Missed Most of Texas</td>\n",
       "      <td>LONGVIEW, Tex.   On the eastern plains of Texa...</td>\n",
       "      <td>{\"'Texas Miracle'\": 'Miracle', 'Texas': 'Texas'}</td>\n",
       "      <td>{'Miracle': {'type': 'item', 'id': 'Q79945462'...</td>\n",
       "      <td>The 'Texas Miracle' Missed Most of Texas LONGV...</td>\n",
       "      <td>The 'Texas Miracle' Missed Most of Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N114474</td>\n",
       "      <td>autos</td>\n",
       "      <td>autosconvertibles</td>\n",
       "      <td>2020 BMW Z4 First Drive Review | More cerebral...</td>\n",
       "      <td>Much has changed with the compact two-seater c...</td>\n",
       "      <td>{'BMW': 'BMW'}</td>\n",
       "      <td>{'BMW': {'type': 'item', 'id': 'Q26678', 'labe...</td>\n",
       "      <td>2020 BMW Z4 First Drive Review | More cerebral...</td>\n",
       "      <td>2020 BMW Z4 First Drive Review | More cerebral...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   News ID      Category              Topic  \\\n",
       "0   N32957  foodanddrink             videos   \n",
       "1   N15327        sports     basketball_nba   \n",
       "2  N117490          news       newspolitics   \n",
       "3  N100097       finance            markets   \n",
       "4  N114474         autos  autosconvertibles   \n",
       "\n",
       "                                            Headline  \\\n",
       "0                      How to Make Spaghetti Pudding   \n",
       "1  Report: Dolan was not interested in paying max...   \n",
       "2     House panel votes to subpoena Kellyanne Conway   \n",
       "3           The 'Texas Miracle' Missed Most of Texas   \n",
       "4  2020 BMW Z4 First Drive Review | More cerebral...   \n",
       "\n",
       "                                           News body  \\\n",
       "0  Similar to bread pudding or rice pudding, this...   \n",
       "1  As if that's the only thing it hinged on NBA f...   \n",
       "2  The House Oversight Committee has voted to sub...   \n",
       "3  LONGVIEW, Tex.   On the eastern plains of Texa...   \n",
       "4  Much has changed with the compact two-seater c...   \n",
       "\n",
       "                                       Title entity  \\\n",
       "0                                                {}   \n",
       "1  {'Dolan': 'Pat Dolan', 'Durant': 'Kevin Durant'}   \n",
       "2                                                {}   \n",
       "3  {\"'Texas Miracle'\": 'Miracle', 'Texas': 'Texas'}   \n",
       "4                                    {'BMW': 'BMW'}   \n",
       "\n",
       "                                      Entity content  \\\n",
       "0                                                 {}   \n",
       "1  {'Pat Dolan': {'type': 'item', 'id': 'Q7143387...   \n",
       "2                                                 {}   \n",
       "3  {'Miracle': {'type': 'item', 'id': 'Q79945462'...   \n",
       "4  {'BMW': {'type': 'item', 'id': 'Q26678', 'labe...   \n",
       "\n",
       "                                             article  \\\n",
       "0  How to Make Spaghetti Pudding Similar to bread...   \n",
       "1  Report: Dolan was not interested in paying max...   \n",
       "2  House panel votes to subpoena Kellyanne Conway...   \n",
       "3  The 'Texas Miracle' Missed Most of Texas LONGV...   \n",
       "4  2020 BMW Z4 First Drive Review | More cerebral...   \n",
       "\n",
       "                                             summary  \n",
       "0                      How to Make Spaghetti Pudding  \n",
       "1  Report: Dolan was not interested in paying max...  \n",
       "2     House panel votes to subpoena Kellyanne Conway  \n",
       "3           The 'Texas Miracle' Missed Most of Texas  \n",
       "4  2020 BMW Z4 First Drive Review | More cerebral...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"Headline\", \"News body\", \"Category\"])\n",
    "\n",
    "df[\"article\"] = df[\"Headline\"].astype(str) + \" \" + df[\"News body\"].astype(str)\n",
    "df[\"summary\"] = df[\"Headline\"].astype(str)\n",
    "\n",
    "# Use SAME 50% sampling as notebook 1\n",
    "df = df.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35812fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.159553</td>\n",
       "      <td>0.148539</td>\n",
       "      <td>0.159553</td>\n",
       "      <td>0.155882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TextRank</td>\n",
       "      <td>0.159553</td>\n",
       "      <td>0.148539</td>\n",
       "      <td>0.159553</td>\n",
       "      <td>0.155882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seq2Seq</td>\n",
       "      <td>0.124501</td>\n",
       "      <td>0.057310</td>\n",
       "      <td>0.112941</td>\n",
       "      <td>0.098250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model   ROUGE-1   ROUGE-2   ROUGE-L   Average\n",
       "0    TF-IDF  0.159553  0.148539  0.159553  0.155882\n",
       "1  TextRank  0.159553  0.148539  0.159553  0.155882\n",
       "2   Seq2Seq  0.124501  0.057310  0.112941  0.098250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df = pd.read_csv(\"C:/Users/Malathi M/OneDrive/Documents/MDTE25/guvi final project/Main project/summarization/from_scratch_summarization_results.csv\")\n",
    "baseline_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7127b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    T5Tokenizer, T5ForConditionalGeneration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "148dcfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7862adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_sentence_embedding(sentence):\n",
    "    inputs = bert_tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=64\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d6f492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d0fd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_extractive_summarize(text, top_n=3):\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    if len(sentences) <= top_n:\n",
    "        return \" \".join(sentences)\n",
    "\n",
    "    embeddings = np.array(\n",
    "        [bert_sentence_embedding(s) for s in sentences]\n",
    "    )\n",
    "\n",
    "    doc_embedding = embeddings.mean(axis=0).reshape(1, -1)\n",
    "    scores = cosine_similarity(embeddings, doc_embedding).flatten()\n",
    "\n",
    "    ranked = scores.argsort()[::-1][:top_n]\n",
    "    ranked = sorted(ranked)\n",
    "\n",
    "    return \" \".join([sentences[i] for i in ranked])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4d31392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "t5_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a8bc363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_summarize(text, max_len=120):\n",
    "    input_text = \"summarize: \" + text[:512]\n",
    "\n",
    "    inputs = t5_tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        summary_ids = t5_model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=max_len,\n",
    "            min_length=40,\n",
    "            num_beams=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    return t5_tokenizer.decode(\n",
    "        summary_ids[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ff40ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"],\n",
    "    use_stemmer=True\n",
    ")\n",
    "\n",
    "def evaluate_model(fn, df, samples=30):\n",
    "    r1, r2, rL = [], [], []\n",
    "\n",
    "    for i in range(samples):\n",
    "        ref = df.iloc[i][\"summary\"]\n",
    "        pred = fn(df.iloc[i][\"article\"])\n",
    "\n",
    "        scores = scorer.score(ref, pred)\n",
    "        r1.append(scores[\"rouge1\"].fmeasure)\n",
    "        r2.append(scores[\"rouge2\"].fmeasure)\n",
    "        rL.append(scores[\"rougeL\"].fmeasure)\n",
    "\n",
    "    return np.mean(r1), np.mean(r2), np.mean(rL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4d91fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT-base (Extractive)</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T5-small (Abstractive)</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.2782</td>\n",
       "      <td>0.2670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  ROUGE-1  ROUGE-2  ROUGE-L  Average\n",
       "0  BERT-base (Extractive)   0.1665   0.1189   0.1520   0.1458\n",
       "1  T5-small (Abstractive)   0.3012   0.2217   0.2782   0.2670"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_scores = evaluate_model(bert_extractive_summarize, df)\n",
    "t5_scores = evaluate_model(t5_summarize, df)\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"BERT-base (Extractive)\",\n",
    "        \"ROUGE-1\": bert_scores[0],\n",
    "        \"ROUGE-2\": bert_scores[1],\n",
    "        \"ROUGE-L\": bert_scores[2]\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"T5-small (Abstractive)\",\n",
    "        \"ROUGE-1\": t5_scores[0],\n",
    "        \"ROUGE-2\": t5_scores[1],\n",
    "        \"ROUGE-L\": t5_scores[2]\n",
    "    }\n",
    "])\n",
    "\n",
    "results[\"Average\"] = results[[\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\"]].mean(axis=1)\n",
    "results.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61c6cbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_transformer_summarizer.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = results.sort_values(\"Average\", ascending=False).iloc[0]\n",
    "\n",
    "best_config = {\n",
    "    \"model\": best_model[\"Model\"],\n",
    "    \"rouge_avg\": best_model[\"Average\"]\n",
    "}\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_config, \"best_transformer_summarizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66970103",
   "metadata": {},
   "source": [
    "REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5949ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"T5-small\": \"t5-small\",\n",
    "    \"T5-base\": \"t5-base\",\n",
    "    \"BART-base\": \"facebook/bart-base\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25402a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"],\n",
    "    use_stemmer=True\n",
    ")\n",
    "\n",
    "def evaluate_transformer(model_name, df, samples=30):\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\",\n",
    "        model=model_name,\n",
    "        tokenizer=model_name,\n",
    "        device=-1  # CPU\n",
    "    )\n",
    "\n",
    "    r1, r2, rL = [], [], []\n",
    "\n",
    "    for i in range(samples):\n",
    "        text = df.iloc[i][\"article\"][:1500]  # truncate for safety\n",
    "        ref = df.iloc[i][\"summary\"]\n",
    "\n",
    "        pred = summarizer(\n",
    "            text,\n",
    "            max_length=80,\n",
    "            min_length=30,\n",
    "            do_sample=False\n",
    "        )[0][\"summary_text\"]\n",
    "\n",
    "        scores = scorer.score(ref, pred)\n",
    "        r1.append(scores[\"rouge1\"].fmeasure)\n",
    "        r2.append(scores[\"rouge2\"].fmeasure)\n",
    "        rL.append(scores[\"rougeL\"].fmeasure)\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": np.mean(r1),\n",
    "        \"rouge2\": np.mean(r2),\n",
    "        \"rougeL\": np.mean(rL)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_results = []\n",
    "\n",
    "for name, model_id in MODELS.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    scores = evaluate_transformer(model_id, df)\n",
    "\n",
    "    transformer_results.append({\n",
    "        \"Model\": name,\n",
    "        \"rouge1\": scores[\"rouge1\"],\n",
    "        \"rouge2\": scores[\"rouge2\"],\n",
    "        \"rougeL\": scores[\"rougeL\"]\n",
    "    })\n",
    "\n",
    "transformer_df = pd.DataFrame(transformer_results)\n",
    "transformer_df[\"Average\"] = transformer_df[\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "].mean(axis=1)\n",
    "\n",
    "transformer_df.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ec87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(\n",
    "    [baseline_df, transformer_df],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "combined_df = combined_df.round(4)\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\n",
    "    \"final_summarization_comparison.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved ‚Üí final_summarization_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e94b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = combined_df.sort_values(\n",
    "    \"Average\",\n",
    "    ascending=False\n",
    ").iloc[0]\n",
    "\n",
    "best_model = {\n",
    "    \"model_name\": best_row[\"Model\"],\n",
    "    \"rouge1\": best_row[\"rouge1\"],\n",
    "    \"rouge2\": best_row[\"rouge2\"],\n",
    "    \"rougeL\": best_row[\"rougeL\"],\n",
    "    \"average\": best_row[\"Average\"],\n",
    "    \"model_type\": \"Transformer\"\n",
    "}\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_model, \"best_transformer_summarizer.pkl\")\n",
    "\n",
    "best_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
